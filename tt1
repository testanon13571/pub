These controls provide hard isolation between models, tenants, and inference runtimes to prevent cross-model interference, cross-tenant data leakage, lateral movement, and privilege escalation in a Tier-1 global bank environment.

| Control ID | Title                                   | Description                                                                                                                   | Threat Description                                                                                                    | Threat(s) Mitigated                                      | Priority      | Affected Component(s)                                 | Implementation Guidance                                                                                                                                                                                                 |
|------------|-----------------------------------------|-------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------|---------------|-------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| SC-AI-101  | Hard Multi-Tenancy Isolation of Model Serving Runtimes | Each business unit, legal entity, or regulatory tenant operates in a completely isolated OpenTrek tenant namespace with dedicated inference pods, separate model weights, and isolated Redis/pgVector connections. No shared runtime processes across tenants. | Cross-tenant data leakage or model output mixing via shared process memory, cache, or inference runtime (high regulatory impact). | OWASP LLM06:2024 (Sensitive Information Disclosure), MITRE ATLAS AML.T0016 (Lateral Movement) | **Must-Have** | Alibaba OpenTrek, Kubernetes, Redis, pgvector         | Deploy OpenTrek using multi-tenant operator mode or separate Helm releases per tenant in dedicated Kubernetes namespaces. Enforce Pod Security Standards “restricted” + NetworkPolicy blocking inter-tenant traffic. |
| SC-AI-102  | Model-Level Container Image & Runtime Hardening | Every deployed model version runs in its own immutable container image built from a bank-approved golden base (distroless + non-root) with a unique model-specific seccomp/bpf profile and zero unnecessary binaries. | Container escape or runtime compromise enabling pivot from one model to another or to the host.                         | MITRE ATLAS AML.TA0008 (Execution), NIST AI RMF Deploy 2.2 | **Must-Have** | Alibaba OpenTrek serving runtime, Kubernetes         | Trivy + Cosign for SBOM & signature enforcement. Use gVisor or Kata Containers for highest isolation; enforce via Kyverno/Gatekeeper policies rejecting non-compliant images.                                      |
| SC-AI-103  | Cryptographic Model Weight Isolation & Key-per-Model | Model weights in MinIO are encrypted at rest with unique per-model (or per-tenant) KMS keys. Keys are never shared and are scoped to the exact model registry entry. | Exfiltration or decryption of one model’s weights granting access to another model’s embedded knowledge or IP.         | OWASP LLM02:2024 (Supply Chain), MITRE ATLAS AML.T0017 (Exfiltration) | **Must-Have** | MinIO, HashiCorp Vault / Thales CipherTrust, PostgreSQL registry | MinIO SSE-KMS with Vault transit engine; key name = model UUID. OpenTrek decrypts on-load using short-lived Vault token (Kubernetes auth). Automatic rotation + zeroisation on decommissioning. |
| SC-AI-104  | Inference-Time Memory & Context Isolation | Enforce strict per-request memory isolation: clear GPU/CPU memory and Python process state after each inference request; prohibit model-to-model in-process calling. | Residual data from one request persisting into another (memory residue side-channel).                                  | OWASP LLM06:2024 (advanced memory attacks)               | **Must-Have** | Alibaba OpenTrek serving runtime                      | Configure OpenTrek/vLLM/TGI with process-per-request or full process recycling. Disable NVIDIA MPS or clear CUDA graphs between requests.                                                                      |
| SC-AI-105  | Model Registry Namespace & Row-Level Security | Logical isolation in central PostgreSQL registry using Row-Level Security (RLS) policies so principals can only see/load models belonging to their tenant or approved domain. | Insider or compromised account loading an unauthorized model into their environment.                                  | NIST AI RMF Govern 4.2, MITRE ATLAS AML.TA0007 (Privilege Escalation) | **Must-Have** | PostgreSQL (central registry)                         | Implement RLS tied to JWT `tenant_id` claim. Example: `CREATE POLICY model_isolation ON models USING (tenant_id = current_setting('app.tenant_id'));`                                                                   |
| SC-AI-106  | Network Micro-Segmentation of Model Serving Endpoints | Zero-trust network policy: inference pods only accept mTLS traffic from OpenTrek API gateway and can only reach their own dedicated Redis/pgVector instances. | Compromised model container performing lateral movement to other models or data stores.                               | MITRE ATLAS AML.TA0016 (Lateral Movement)                | **Must-Have** | Kubernetes NetworkPolicy, Cilium/Calico               | Cilium NetworkPolicy with mTLS enforcement. Allow ingress only from gateway label; egress only to labeled Redis/pgvector per tenant.                                                                                     |
| SC-AI-107  | Model-Specific Secrets & Configuration Isolation | No shared secrets or configuration across models. Each model version has its own Kubernetes Secret/ConfigMap containing only what that exact model needs. | Secret leakage from one model granting unintended capabilities (e.g., tool credentials) to another.                    | OWASP LLM08:2024 (Excessive Agency)                      | **Should-Have** | Kubernetes Secrets, OpenTrek                          | Use Sealed Secrets or Vault CSI driver to inject per-model secrets at deployment time, referenced by model UUID.                                                                                                           |
| SC-AI-108  | Canary & Shadow Model Isolation         | New model versions deployed into physically separated canary clusters/namespaces with synthetic traffic only; production traffic never mixes with canary until full promotion. | Faulty or backdoored model version contaminating production during A/B or shadow testing.                              | NIST AI RMF Deploy 3, MITRE ATLAS AML.TA0001 (Supply Chain) | **Should-Have** | Alibaba OpenTrek, Argo Rollouts / Flagger             | Argo Rollouts with separate OpenTrek tenant pools for canary; traffic mirrored but responses discarded until manual sign-off.                                                                                     |

**Implementation Recommendation**  
Deploy all **Must-Have** controls (SC-AI-101 through SC-AI-106) before any production traffic is allowed. This baseline satisfies ECB SSRF, FED SR 11-7, MAS TRM, and PRA SS2/21 requirements for hard model and tenant isolation in supervised AI systems.
