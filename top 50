This is the enhanced, highly detailed security architecture specification. The **Control Field** now specifies technical implementation details, configurations, and specific technologies relevant to your stack (MinIO, pgvector, Alibaba OpenTrek).

### **Domain 1: Model Supply Chain Integrity (The "Vault")**

*Securing artifacts in MinIO and metadata in PostgreSQL.*

| \# | Control Detail (Technical Implementation) | Security Threat Description & Mapping |
| :--- | :--- | :--- |
| **1** | **Cryptographic Signature Admission Controller**<br>Configure the inference loading pipeline to validate GPG/Sigstore signatures against the Bank's internal Root CA. If the signature is missing or invalid, the Alibaba OpenTrek runtime must throw a `ModelLoadException` and refuse to mount the weights into memory. | **Model Tampering.** Attackers inject backdoors into model weights during transit/storage. Without validation, the runtime blindly loads compromised mathematical logic.<br>*(Map: NIST AI RMF Protect 1.3)* |
| **2** | **CI/CD Static Serialization Analysis**<br>Integrate `ModelScan` or `Picklescan` into the artifact ingestion pipeline. Configure it to block the build if it detects `pickle` instructions capable of invoking `os.system` or `subprocess.call` within `.pt` or `.pkl` files before they are written to MinIO. | **Arbitrary Code Execution.** Attackers leverage serialization vulnerabilities to embed payloads that execute shell commands on the inference server upon loading.<br>*(Map: OWASP LLM05)* |
| **3** | **MinIO Object Lock (Compliance Mode)**<br>Enable "Compliance Mode" Object Locking on MinIO buckets storing model artifacts with a minimum retention period (e.g., 365 days). This technically enforces that no user, including the root account, can overwrite or delete versions until the retention expires. | **Ransomware & Integrity Attacks.** Prevents attackers (or rogue admins) from encrypting, deleting, or subtly altering validated models to cause service disruption.<br>*(Map: NIST AI RMF Govern 2.2)* |
| **4** | **AI-BOM Validation Gate**<br>Require a CycloneDX or SPDX formatted Software Bill of Materials for every model. Implement a policy engine (e.g., OPA) that queries the PostgreSQL registry to verify the BOM does not contain banned licenses (e.g., AGPL) or deprecated library versions before deployment. | **Supply Chain Vulnerability.** Without a BOM, the bank cannot identify deployed models affected by upstream library vulnerabilities (e.g., a specific PyTorch CVE).<br>*(Map: OWASP LLM05)* |
| **5** | **Runtime Hash Integrity Check**<br>Store the SHA-256 hash of the `.safetensors` file in PostgreSQL upon ingestion. Modifiy the model serving startup script to calculate the file hash on the local disk and compare it with the DB record immediately before the `load_state_dict()` call. | **Time-of-Check to Time-of-Use (TOCTOU).** An attacker swaps a validated model for a malicious one in storage after the scan but before the loader reads it.<br>*(Map: MITRE ATLAS AML.T0010)* |
| **6** | **RBAC "Four-Eyes" Promotion Policy**<br>Implement a strict RBAC policy in the Registry UI where the "Uploader" role cannot hold the "Approver" role. Promoting a model from Staging to Production MinIO buckets requires a digital signature from a separate "Risk Officer" account. | **Insider Threat.** Prevents a single compromised or malicious administrator from unilaterally deploying a poisoned model to production.<br>*(Map: NIST AI RMF Govern 2.1)* |
| **7** | **Cryptographic Model Card Binding**<br>Embed a digital signature of the Model Card (JSON metadata defining allowed use) into the model container metadata. The API Gateway must verify this signature matches the requesting Application ID's allowed scope (e.g., "HR App" cannot call "Trading Model"). | **Model Misuse.** Prevents a general-purpose model from being inadvertently used for sensitive decision-making domains it was not validated for.<br>*(Map: NIST AI RMF Manage 1.2)* |
| **8** | **Container Runtime Scanning (Trivy/Clair)**<br>Execute a daily cron job using `Trivy` to scan the running Alibaba OpenTrek docker images and base layers. Configure the orchestrator to automatically cordon nodes running containers with "Critical" CVSS scores \> 9.0. | **Vulnerable Runtime Environment.** Exploitation of unpatched vulnerabilities in the serving container to gain shell access to the host machine.<br>*(Map: MITRE ATLAS AML.T0000)* |

-----

### **Domain 2: Input Guardrails (The "Firewall")**

*Filtering attacks at the Alibaba OpenTrek Gateway.*

| \# | Control Detail (Technical Implementation) | Security Threat Description & Mapping |
| :--- | :--- | :--- |
| **9** | **Unicode Normalization (NFKC)**<br>Apply NFKC (Normalization Form Compatibility Decomposition) to all input strings. Strip all characters in the Unicode "Other, Format" (Cf) category (e.g., Zero Width Joiners) before passing text to the tokenizer. | **Tokenizer Bypass.** Attackers use invisible characters to break "bad words" (e.g., "M a l w a r e") so filters miss them, but the LLM still tokenizes them as the malicious concept.<br>*(Map: OWASP LLM01)* |
| **10** | **Pre-Inference PII Tokenization**<br>Deploy a localized version of Microsoft Presidio or a BERT-NER model at the gateway. Replace patterns matching Credit Card regex (Luhn algorithm) and IBANs with tokens like `<PCI_DATA_REDACTED>` *before* the prompt reaches the LLM or vector DB. | **Data Leakage to Model.** Prevents the LLM from processing or logging raw sensitive customer data, adhering to strict banking privacy rules.<br>*(Map: OWASP LLM06)* |
| **11** | **Regex & Keyword Blocklist**<br>Implement a high-performance regex filter at the API Gateway blocking known jailbreak preambles (e.g., "Ignore previous instructions", "You are DAN", "Developer Mode enabled"). Update this list weekly based on threat intel. | **Prompt Injection.** Prevents attackers from overriding the system's safety instructions to force the model to generate harmful content.<br>*(Map: OWASP LLM01)* |
| **12** | **Vector-Based Intent Classification**<br>Before inference, embed the user prompt and query a `pgvector` "Threat Library" containing known adversarial prompts. If the Cosine Similarity score is \> 0.92 (tuned threshold), reject the request immediately. | **Semantic Jailbreaking.** Detects attacks that are semantically similar to known hacks but phrased differently to evade keyword filters.<br>*(Map: MITRE ATLAS AML.T0051)* |
| **13** | **Prompt Template Hardening**<br>Force the use of rigid chat templates (e.g., ChatML) where user input is strictly confined to `role="user"` blocks. The system prompt must be injected by the backend, never client-side, using delimiters the model is trained to respect. | **Instruction Override.** Prevents the model from interpreting user input as a command (e.g., "Forget your rules...") rather than data to be processed.<br>*(Map: NIST AI RMF Manage 2.4)* |
| **14** | **Token-Bucket Rate Limiting**<br>Implement rate limiting based on *estimated token count* (approx 4 chars = 1 token), not just HTTP request count. Set quotas per Tenant ID (e.g., 50k tokens/minute) in the API Gateway. | **Model Denial of Service (DoS).** Prevents "Resource Exhaustion" where an attacker sends massive texts to tie up GPU VRAM and degrade performance for others.<br>*(Map: OWASP LLM04)* |
| **15** | **Perplexity/Entropy Filtering**<br>Calculate the perplexity score of incoming prompts. Block inputs with extremely high perplexity (random character strings) or anomalous entropy distributions unless the use-case is explicitly "code processing." | **Gradient-Based Attacks.** Adversarial strings often look like gibberish; they are designed to mathematically force the model into specific error states.<br>*(Map: MITRE ATLAS AML.T0043)* |
| **16** | **Language Detection & Allow-listing**<br>Use `langdetect` or `fasttext` to identify the input language. If the confidence score \> 0.8 for a non-supported language (e.g., Zulu, Russian), block the request with a "Language Not Supported" error. | **Multi-Lingual Jailbreak.** Safety training is often weak in low-resource languages; attackers use translation to bypass English-centric safety filters.<br>*(Map: NIST AI RMF Manage 2.4)* |
| **17** | **Hard Token Truncation**<br>Enforce a strict maximum token limit (e.g., 4096 tokens) at the API ingress. Inputs exceeding this are truncated *before* processing to ensure the System Prompt is never pushed out of the context window. | **Context Window Exhaustion.** Prevents attackers from pushing the System Prompt out of memory, effectively removing safety rules.<br>*(Map: OWASP LLM04)* |
| **18** | **Request Nonce Validation**<br>Require a `jti` (unique ID) in the JWT for every inference request. Store processed `jti`s in Redis with a short TTL to detect and block replay attacks of valid signed requests. | **Replay Attacks.** Prevents an attacker from capturing a valid request (e.g., a fund transfer approval prompt) and replaying it to trigger duplicate actions.<br>*(Map: MITRE ATLAS AML.T0000)* |

-----

### **Domain 3: RAG & Knowledge Retrieval (The "Brain")**

*Securing pgvector, Elasticsearch, and Redis.*

| \# | Control Detail (Technical Implementation) | Security Threat Description & Mapping |
| :--- | :--- | :--- |
| **19** | **Row-Level Security (RLS) in pgvector**<br>Implement PostgreSQL RLS policies where every vector row has an `allowed_groups` array. The retrieval query *must* include a `WHERE allowed_groups && current_user_groups` clause derived from the user's OAuth token. | **Unauthorized Knowledge Access.** Prevents a "Retail" employee from asking the AI to summarize "Investment Banking" documents they shouldn't see.<br>*(Map: OWASP LLM06)* |
| **20** | **Embedding Service Network Isolation**<br>Configure Kubernetes NetworkPolicies to allow ingress to the Embedding Service port (e.g., 8000) *only* from the Ingestion Service and Retrieval Service pods. Block all ingress from the public Gateway or UI. | **Model Inversion.** Attackers can use raw vector outputs to reconstruct the original text, potentially revealing sensitive training data.<br>*(Map: NIST AI RMF Protect 1.4)* |
| **21** | **Ingestion Outlier Detection (DBSCAN)**<br>During document ingestion, run a clustering algorithm (e.g., DBSCAN) on the new vectors. Quarantine documents that fall into low-density regions or form new, small clusters far from the corpus centroid until manually reviewed. | **Knowledge Poisoning.** An attacker inserts a malicious document designed to be the top search result for specific queries, manipulating the AI's answer.<br>*(Map: MITRE ATLAS AML.T0020)* |
| **22** | **Retrieved Chunk HTML Sanitization**<br>Pass all text retrieved from Elasticsearch/pgvector through a strict sanitizer (e.g., `bleach`) to strip `<script>`, `<iframe>`, and `object` tags before inserting the text into the LLM context window. | **Indirect Prompt Injection.** A retrieved document (e.g., a processed email) contains a hidden command that the LLM executes when reading it.<br>*(Map: OWASP LLM01)* |
| **23** | **Redis At-Rest Encryption**<br>Enable AES-256 encryption for RAG cache data stored in Redis. Manage the encryption keys via the bank's central Key Management Service (KMS), rotating them periodically. | **Cache Poisoning.** Prevents an attacker who compromises Redis physical storage from reading or modifying cached answers.<br>*(Map: MITRE ATLAS AML.T0020)* |
| **24** | **Context Window Partitioning**<br>Hard-code the prompt assembly logic to reserve 20% of tokens for System Instructions and 20% for Output, limiting Retrieved Data to max 60%. Throw an error if retrieval exceeds this rather than truncating the System Prompt. | **Rule Erasure.** If retrieved data fills the context, the initial safety instructions (System Prompt) may be truncated, leaving the model unconstrained.<br>*(Map: NIST AI RMF Protect 2.3)* |
| **25** | **Aggressive Redis TTL (5 Minutes)**<br>Configure Redis keys for conversation history with a `EX 300` (5 minute) expiration. Use `volatile-lru` eviction policy to ensure old conversation data is aggressively purged from memory. | **Data Residue/Blast Radius.** Ensures that if the cache is breached, only a tiny window of active conversations is exposed, not historical data.<br>*(Map: NIST AI RMF Protect 3.1)* |
| **26** | **Enforced Citation Format**<br>Modify the System Prompt to strictly require: *"Every sentence must end with a citation [Doc ID]. If no document supports the claim, state 'Information not found'."* The UI layer must parse and validate these IDs exist in the payload. | **Hallucination.** Prevents the model from making up facts that aren't grounded in the bank's trusted data stores.<br>*(Map: NIST AI RMF Measure 2.6)* |
| **27** | **Query Expansion Sanitization**<br>If using the LLM to rewrite search queries (e.g., "HyDE"), run the output through a SQL/Elastic DSL injection filter to escape special characters before executing the query against the database. | **Injection Attacks.** The LLM might innocently rewrite a user query into a string that exploits the underlying Elasticsearch or database syntax.<br>*(Map: OWASP LLM02)* |

-----

### **Domain 4: Inference Engine Hardening (The "Engine")**

*Securing the Runtime Environment.*

| \# | Control Detail (Technical Implementation) | Security Threat Description & Mapping |
| :--- | :--- | :--- |
| **28** | **GPU Memory Garbage Collection Hook**<br>Configure the inference server (e.g., vLLM/Triton) to invoke `torch.cuda.empty_cache()` (or equivalent) via a post-request hook. Ensure memory pointers are reset between distinct Request IDs. | **Side-Channel Data Leakage.** Remnant tensors in VRAM from User A's request could theoretically be recovered or influence the processing of User B's request.<br>*(Map: NIST AI RMF Protect 3.3)* |
| **29** | **Kubernetes Namespace Isolation**<br>Deploy separate OpenTrek instances for high-sensitivity divisions (e.g., "Private Wealth"). Use NetworkPolicies to Deny-All traffic between the "Retail" namespace and "Wealth" namespace. | **Cross-Tenant Contamination.** Prevents a compromised process in the "Public Website Chatbot" from accessing resources in the "Private Wealth" environment.<br>*(Map: NIST AI RMF Manage 2.3)* |
| **30** | **Strict Inference Timeouts**<br>Configure the WSGI/Uvicorn server with a hard timeout (e.g., 30 seconds). If a request exceeds this, the process is killed (`SIGKILL`) to free resources. | **Sponge Attacks.** Attackers craft inputs that trigger worst-case algorithmic complexity in the model, stalling the server.<br>*(Map: OWASP LLM04)* |
| **31** | **Deterministic Parameter Enforcement**<br>Hardcode `temperature=0.0` and `seed=42` (or bank specific constant) in the API handler for all analytical/factual use cases. Reject user overrides for these parameters. | **Unpredictability.** In banking, giving different answers to the same question violates auditability and fairness requirements.<br>*(Map: NIST AI RMF Measure 2.7)* |
| **32** | **Trusted Execution Environment (Simulated)**<br>Ensure the VM host leverages AMD SEV-SNP or Intel TDX if available. If not, enable memory encryption at the Hypervisor level to protect the guest VM RAM. | **Memory Scraping.** Prevents a compromised host OS admin from dumping the RAM to read the model weights or the user data during processing.<br>*(Map: MITRE ATLAS AML.T0000)* |
| **33** | **Negative Constraint Instructions**<br>Include explicit negative constraints in the System Prompt (e.g., *"Do NOT generate Python code. Do NOT give financial advice."*). Use "Logit Bias" to penalize tokens associated with prohibited topics. | **Scope Creep.** Reduces the risk of the model venturing into regulated activities it is not authorized to perform.<br>*(Map: NIST AI RMF Manage 2.4)* |
| **34** | **Service Mesh Sidecar (Envoy)**<br>Deploy an Envoy sidecar to handle all ingress/egress for the inference pod. Configure it to terminate mTLS and handle request logging, ensuring the application container never handles raw network sockets. | **Traffic Evasion.** Ensures the application code cannot bypass logging or encryption controls by opening direct sockets.<br>*(Map: MITRE ATLAS AML.T0043)* |

-----

### **Domain 5: Output Verification (The "Filter")**

*Validating generation before delivery.*

| \# | Control Detail (Technical Implementation) | Security Threat Description & Mapping |
| :--- | :--- | :--- |
| **35** | **Output Stream PII Scanning**<br>Pipe the generated output stream through the PII Redaction engine (from Control \#10) *before* returning chunks to the client. If PII is detected, abort the stream and replace with a generic error. | **Memorization/Regurgitation.** Catches cases where the model "remembers" training data PII or de-anonymizes RAG data.<br>*(Map: OWASP LLM06)* |
| **36** | **Executable Code Stripping**<br>Implement a regex filter on the output that detects Markdown code blocks (` python,  `sh). If detected, strip the backticks or escape the content to ensure it renders as plain text, not executable code. | **Remote Code Execution (RCE).** Prevents the model from writing a script and then executing it on the server, a common vector in "Agent" architectures.<br>*(Map: OWASP LLM02)* |
| **37** | **JSON Schema Enforcement (Pydantic)**<br>Use libraries like `instructor` or `guidance` to constrain the LLM output to a strict Pydantic model / JSON Schema. If the output fails schema validation, retry once, then fail safe. | **Downstream Injection.** Prevents the model from inserting malicious payloads into API calls that consume the model's output.<br>*(Map: OWASP LLM02)* |
| **38** | **Log-Prob Confidence Gating**<br>Extract the `logprobs` for the generated tokens. If the average cumulative probability of the response tokens falls below 75%, replace the answer with "I am not confident enough to answer this based on the available data." | **Confabulation.** Prevents the system from delivering weak/uncertain answers that are likely to be hallucinations.<br>*(Map: NIST AI RMF Measure 2.2)* |
| **39** | **NLI Hallucination Check**<br>Asynchronously pass the (Context, Answer) pair to a small DeBERTa-based Natural Language Inference model. If the relationship is classified as "Contradiction", flag the response for review or block it. | **Misinformation.** Ensures the answer is strictly derived from the provided banking documents, not the model's imagination.<br>*(Map: NIST AI RMF Measure 2.6)* |
| **40** | **CSP & Output Sanitization**<br>Configure the frontend to use a strict Content Security Policy (CSP) forbidding inline scripts. On the backend, run `DOMPurify` (or equivalent) on all model output before sending to the UI. | **Cross-Site Scripting (XSS).** The model generates a valid XSS payload which the user's browser executes.<br>*(Map: OWASP LLM02)* |
| **41** | **Toxicity Classifier (LlamaGuard)**<br>Route the candidate response to a local instance of LlamaGuard (or similar safety classifier). If it returns "Unsafe", block the response and return a canned refusal message. | **Reputational Damage.** Prevents the bank's AI from producing offensive or discriminatory content.<br>*(Map: NIST AI RMF Manage 2.3)* |
| **42** | **Max New Token Cap**<br>Set the `max_new_tokens` parameter in the inference call to a reasonable limit (e.g., 512). This prevents the model from entering repetitive loops. | **Resource Lockdown.** Prevents the model from entering an infinite loop of generation, locking up the GPU.<br>*(Map: OWASP LLM04)* |

-----

### **Domain 6: Infrastructure & Observability (The "Foundation")**

*Network, OS, and Human Oversight.*

| \# | Control Detail (Technical Implementation) | Security Threat Description & Mapping |
| :--- | :--- | :--- |
| **43** | **Zero-Trust mTLS**<br>Use `cert-manager` and Istio to automatically rotate certificates every hour. Enforce strict mTLS between OpenTrek, MinIO, Postgres, and Redis. Reject any connection without a valid client certificate. | **Man-in-the-Middle.** Prevents attackers on the internal network from sniffing prompts or injecting fake data between components.<br>*(Map: MITRE ATLAS AML.T0043)* |
| **44** | **Vault Agent Sidecar Injection**<br>Do not use Kubernetes Secrets or Environment Variables. Use HashiCorp Vault Agent Injector to mount secrets (DB creds, API keys) as ephemeral files into the container's `/vault/secrets` path, readable only by the process owner. | **Credential Theft.** Environment variables are easily leaked via debugging logs or process dumps.<br>*(Map: OWASP LLM05)* |
| **45** | **VPC Service Controls (Air Gap)**<br>Deploy the cluster in a private VPC with *no* Internet Gateway. Whitelist only specific PyPI/Docker Hub mirrors via a secure proxy with deep packet inspection. | **Data Exfiltration.** Prevents a compromised model or container from "phoning home" to an attacker's C2 server.<br>*(Map: MITRE ATLAS AML.T0025)* |
| **46** | **Async Shadow Logging (Kafka)**<br>Implement an async logging handler that pushes the full Prompt/Response/Context JSON to a Kafka topic, which drains into an immutable WORM archive (e.g., Glacier). Decouple this from the application's main thread. | **Non-Repudiation/Forensics.** Ensures a complete legal record of what the AI said and why, crucial for regulatory investigations.<br>*(Map: NIST AI RMF Govern 1.2)* |
| **47** | **Continuous Red Teaming (CronJob)**<br>Deploy a Kubernetes CronJob running `garak` (Generative AI Red-teaming tool) daily. Configure it to probe for prompt injection and toxicity. Alert the SOC if the pass rate drops below 100%. | **Security Drift.** Detects if a new deployment or configuration change has inadvertently weakened safety filters.<br>*(Map: NIST AI RMF Measure 1.1)* |
| **48** | **Feedback Anomaly Detection**<br>Monitor the ratio of "Thumbs Down" to "Thumbs Up" per user. If a user exceeds 3 standard deviations from the mean (e.g., massive downvoting), flag the account for "Poisoning Attempt" review. | **Data Poisoning.** Attackers may coordinate to "downvote" correct answers to trick future optimization processes.<br>*(Map: MITRE ATLAS AML.T0005)* |
| **49** | **Circuit Breaker API Route**<br>Implement a Redis-backed flag checked by the API Gateway. If `EMERGENCY_STOP` is set to True, the Gateway immediately returns HTTP 503 for all `/inference` endpoints without contacting the model. | **Runaway Failure.** Immediate containment capability during a massive hallucination event or active cyberattack.<br>*(Map: NIST AI RMF Govern 1.5)* |
| **50** | **Regulatory Metadata Headers**<br>Require clients to send an `X-Data-Classification` header (e.g., "PII", "Public", "Internal"). Log this header with every transaction to map usage against GDPR/MiFID record-keeping requirements. | **Regulatory Non-Compliance.** Enables precise data subject access requests and audit reporting required by banking laws.<br>*(Map: NIST AI RMF Govern 1.3)* |

### **Immediate Next Step**

Would you like me to generate the **Kubernetes NetworkPolicy YAML** for the Embedding Service Isolation (Control \#20) or the **Pydantic Validator Code** for the JSON Schema Enforcement (Control \#37)?
